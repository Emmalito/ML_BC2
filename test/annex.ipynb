{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA\n",
    "\n",
    "This last part is dedicated to the PCA method. As we will see, there will be 4 PC that account for a large amount of variance. This is quite huge because doing PCA we were expected to reduce the problem to dimension 2 or at least 3 in order to have better visualization and reduction of the problem.\n",
    "\n",
    "Thus we will not use the PC space because it doesn't simplify the case as we already avoid the two feature by our interpretation\n",
    "\n",
    "Here the PCA :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(X_train) # we fit the dataset \n",
    "print('first principal component direction:', pca.components_[:,0]) # we extract the principal components directions\n",
    "\n",
    "explained = pca.explained_variance_ratio_  # and the corresponding explained variance\n",
    "print('explained variance:', explained)\n",
    "\n",
    "T = pca.transform(X_train)  #transform into PC space\n",
    "\n",
    "explained_variance = np.cumsum(explained) / sum(explained)\n",
    "explained_variance = np.insert(explained_variance, 0, 0.)\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(range(len(explained_variance)), explained_variance)\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Explained variance')\n",
    "plt.xticks(range(len(explained_variance)))\n",
    "plt.yticks(np.arange(0., 1.1, 0.1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def metrics(cm, isInc):\n",
    "    TN = cm[0][0]\n",
    "    FP = cm[0][1]\n",
    "    FN = cm[1][0] \n",
    "    TP = cm[1][1]\n",
    "    TPR = TP/(TP+FN) ; P = TP/(TP+FP) \n",
    "    TNR = (TN/(TN+FP)) ; F1 = (2*P*TPR)/(P+TPR)\n",
    "    acc = (TP+TN)/(TP+TN+FP+FN)\n",
    "    if isInc:\n",
    "        print(\"Measures for IncomeInvestment:\")\n",
    "    else:\n",
    "        print(\"Measures for AccumulationInvestment\")\n",
    "    print(f'Sensitivity = {TPR:2.2%} ;  Specificity = {TNR:2.2%} ; Precision = {P:2.2%} ; F1 score = {F1:2.2%} ; Accuracy = {acc:2.2%}', \"\\n\")\n",
    "\n",
    "def confusionMat(predInc, predAcc):\n",
    "    cm1 = confusion_matrix(Inc_test, predInc)\n",
    "    cm2 = confusion_matrix(Acc_test, predAcc)\n",
    "\n",
    "    #Plot\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15,5))\n",
    "    group_names = [\"True Neg\",\"False Pos\",\"False Neg\",\"True Pos\"]\n",
    "    group_counts1 = [\"{0:0.0f}\".format(value) for value in cm1.flatten()]\n",
    "    group_counts2 = [\"{0:0.0f}\".format(value) for value in cm2.flatten()]\n",
    "    group_percentages1 = [\"{0:.2%}\".format(value) for value in cm1.flatten()/np.sum(cm1)]\n",
    "    group_percentages2 = [\"{0:.2%}\".format(value) for value in cm2.flatten()/np.sum(cm2)]\n",
    "    labels1 = np.asarray([f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts1,group_percentages1)]).reshape(2,2)\n",
    "    labels2 = np.asarray([f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts2,group_percentages2)]).reshape(2,2)\n",
    "    sns.heatmap(cm1, annot=labels1, fmt=\"\", cmap='Blues', ax=axes[0])\n",
    "    sns.heatmap(cm2, annot=labels2, fmt=\"\", cmap='Blues', ax=axes[1])\n",
    "    axes[0].set_title(\"IncomeInvestment\")\n",
    "    axes[1].set_title(\"AccumulationInvestment\")\n",
    "\n",
    "    #Metrics\n",
    "    metrics(cm1, 1)\n",
    "    metrics(cm2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PCA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/oualid/Ensimag/POLIMI/Fintech/project/ML_BC2/test/annex.ipynb Cell 4'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/oualid/Ensimag/POLIMI/Fintech/project/ML_BC2/test/annex.ipynb#ch0000004?line=0'>1</a>\u001b[0m pca_test \u001b[39m=\u001b[39m PCA(n_components\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/oualid/Ensimag/POLIMI/Fintech/project/ML_BC2/test/annex.ipynb#ch0000004?line=1'>2</a>\u001b[0m pca_test\u001b[39m.\u001b[39mfit(X_train)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/oualid/Ensimag/POLIMI/Fintech/project/ML_BC2/test/annex.ipynb#ch0000004?line=2'>3</a>\u001b[0m T \u001b[39m=\u001b[39m pca_test\u001b[39m.\u001b[39mtransform(X_train) \n",
      "\u001b[0;31mNameError\u001b[0m: name 'PCA' is not defined"
     ]
    }
   ],
   "source": [
    "pca_test = PCA(n_components=1)\n",
    "pca_test.fit(X_train)\n",
    "T = pca_test.transform(X_train) \n",
    "\n",
    "model = RF()\n",
    "model.fit(X_train, Acc_train)\n",
    "print(model.score(X_test, Acc_test))\n",
    "pred_acc = model.predict(X_test)\n",
    "data = X_test[pred==1]\n",
    "df = pd.DataFrame(data, columns=[\"Age\", \"Gender\", \"FamilyMembers\", \"RatioFeature\", \"logIncome\", \"logWealth\"])\n",
    "\n",
    "model.fit(X_train, Inc_train)\n",
    "print(model.score(X_test, Inc_test))\n",
    "pred_inc = model.predict(X_test)\n",
    "confusionMat(pred_inc, pred_acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result goes beyond our expectation. We can see that the first principal component explains more than 99% of the total variance. The dimension space can be reduce from 4 to 1 component.\n",
    "\n",
    "We have to understand what does it mean: \n",
    "- First, the problem seems not lineary separable if all the variance is on the first component, we can not separate the datas\n",
    "- \n",
    "\n",
    "## CONTINUER L'EXPLICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "need, no_need = T[Acc_train==1], T[Acc_train==0]\n",
    "need_inc, no_need_inc = T[Inc_train==1], T[Inc_train==0]\n",
    "\n",
    "#Plot\n",
    "fig, axis = plt.subplots(2, 2, figsize=(15,10))\n",
    "axes[0].set_title(\"Datas for AccumulationInvestment target\")\n",
    "axis[0,0].scatter(need[:, 0], need[:, 1], label='need')\n",
    "#axis[0,0].scatter(no_need[:, 0], no_need[:, 1], label='no need', marker='x')\n",
    "axis[0,0].set(xlabel='pc1', ylabel='pc2')\n",
    "axis[0,0].grid()\n",
    "axis[0,0].legend()\n",
    "\n",
    "axis[0,1].scatter(no_need[:, 0], no_need[:, 1], label='no need', marker='x') #(need[:, 2], need[:, 3], label='need')\n",
    "#axis[0,1].scatter(no_need[:, 0], no_need[:, 2], label='no need', marker='x')\n",
    "axis[0,1].set(xlabel='pc1', ylabel='pc2')\n",
    "axis[0,1].grid()\n",
    "axis[0,1].legend()\n",
    "\n",
    "axes[1].set_title(\"Datas for IncomeInvestmentincome target\")\n",
    "axis[1,0].scatter(need_inc[:, 0], need_inc[:, 1], label='need')\n",
    "#axis[1,0].scatter(no_need_inc[:, 0], no_need_inc[:, 1], label='no need', marker='x')\n",
    "axis[1,0].set(xlabel='pc1', ylabel='pc2')\n",
    "axis[1,0].grid()\n",
    "axis[1,0].legend()\n",
    "\n",
    "axis[1,1].scatter(no_need_inc[:, 0], no_need_inc[:, 1], label='no need', marker='x') #(need_inc[:, 2], need_inc[:, 3], label='need')\n",
    "#axis[1,1].scatter(no_need_inc[:, 2], no_need_inc[:, 3], label='no need', marker='x')\n",
    "axis[1,1].set(xlabel='pc1', ylabel='pc2')\n",
    "axis[1,1].grid()\n",
    "axis[1,1].legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
